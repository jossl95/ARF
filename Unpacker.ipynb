{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpacker\n",
    "\n",
    "This script unpacks and untars archive files from the Dark Net Market Archives (Brawnen, 2017). These files are read into memory to be able to extract data from HTML-files about market behavior of the 11 biggest markets in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"/Volumes/Extreme SSD\"\n",
    "DATA_DIR = os.path.join(MAIN_DIR, \"data\")\n",
    "\n",
    "os.chdir(os.path.join(DATA_DIR, \"archive\"))\n",
    "files = os.listdir(os.path.join(DATA_DIR, \"archive\"))\n",
    "files.sort()\n",
    "file_name = os.path.join(os.path.join(DATA_DIR, \"archive\"), files[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition\n",
    "\n",
    "In the following section functions are defined to decompress and untar the market archive. This function does ... things: \n",
    "1. It opens the tarball\n",
    "2. It asserts valid files to be untarred to be sorted into memory\n",
    "3. It writes a logbook for data quality purposes, such that in saves the name, time, mode, type and size of the unpacked files. \n",
    "4. It extracts valid files and saves in a designated folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get name of market\n",
    "def market_name(file_name):\n",
    "    \"\"\"\n",
    "    This function read the market name from the tar-file name\n",
    "    \"\"\"\n",
    "    return file_name.split('/')[-1].split('.')[0]\n",
    "\n",
    "\n",
    "def extract_market(_tar, _path, _members):\n",
    "    _tar.extractall(path=_path, members=_members)\n",
    "\n",
    "\n",
    "def untar_market(file_name):\n",
    "    junk = ('img', 'jpg', 'jpeg', 'png', 'css', 'eot',\n",
    "            'woff', 'svg', 'woff', 'ttf', 'eot?', 'ico')\n",
    "\n",
    "    # opening the zip file in READ mode\n",
    "    with tarfile.open(file_name) as tar:\n",
    "        members = tar.getmembers()\n",
    "        valid_files = [\n",
    "            tarinfo for tarinfo in members\n",
    "            if tarinfo.name.split('.')[-1].lower() not in junk\n",
    "        ]\n",
    "\n",
    "        # writing log file for file extraction\n",
    "        log_file = os.path.join(DATA_DIR, \"logs\", \"\".join(\n",
    "            [\"log_\", market_name(file_name), \".csv\"]))\n",
    "        with open(log_file, 'w', newline='', encoding='utf8') as file:\n",
    "            l = ['name', 'time', 'mode', 'type', 'size']\n",
    "            writer = csv.writer(\n",
    "                file, quoting=csv.QUOTE_NONNUMERIC, delimiter=';')\n",
    "            writer.writerow(l)\n",
    "\n",
    "        for info in valid_files:\n",
    "            _name = info.name\n",
    "            _time = time.ctime(info.mtime)\n",
    "            _mode = oct(info.mode)\n",
    "            _type = info.type\n",
    "            _size = info.size\n",
    "\n",
    "            with open(log_file, 'a', encoding='utf-16', errors=\"surrogateescape\") as file:\n",
    "                l = [_name, _time, _mode, _type, _size]\n",
    "                writer = csv.writer(\n",
    "                    file, quoting=csv.QUOTE_NONNUMERIC, delimiter=';')\n",
    "                writer.writerow(l)\n",
    "\n",
    "        # extracting files using multiprocessing\n",
    "        extract_market(tar, os.path.join(DATA_DIR, \"unpacked\"), valid_files)\n",
    "\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Selection\n",
    "\n",
    "The 11 biggest markets were selected to be unpacked. The code below makes a list of selected markets sequentially makes a list of indices to iterate more efficiently over the list if files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "markets = [\"outlawmarket.tar.xz\", \n",
    "           \"agora.tar.xz\", \n",
    "           \"nucleus.tar.xz\", \n",
    "           \"silkroad2.tar.xz\", \n",
    "           \"abraxas.tar.xz\", \n",
    "           \"diabolus.tar.xz\",\n",
    "           \"themarketplace.tar.xz\",\n",
    "           \"cryptomarket.tar.xz\",\n",
    "           \"cloudnine.tar.xz\",\n",
    "           \"hydra.tar.xz\",\n",
    "           \"alphabay.tar.xz\"]\n",
    "\n",
    "selected_markets = [files[i] for i in [files.index(m) for m in markets]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk Unpack\n",
    "\n",
    "Unpacks all the markets that have not been read into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_all(list_of_files):\n",
    "    for file in list_of_files:\n",
    "        # asserts whether data has already been unpacked\n",
    "        if (os.path.exists(os.path.join(DATA_DIR, \"unpacked\", file.split(\".\")[0]))):\n",
    "            print(f\"%s has already been loaded into memory \\n\" % file)\n",
    "        else:\n",
    "            t = time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime())\n",
    "            print(f\"%s is being unpacked. \\nstarted on %s. \\n\" % (file, t))\n",
    "            untar_market(os.path.join(DATA_DIR, \"archive\", file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlawmarket.tar.xz has already been loaded into memory \n",
      "\n",
      "agora.tar.xz has already been loaded into memory \n",
      "\n",
      "nucleus.tar.xz has already been loaded into memory \n",
      "\n",
      "silkroad2.tar.xz has already been loaded into memory \n",
      "\n",
      "abraxas.tar.xz has already been loaded into memory \n",
      "\n",
      "diabolus.tar.xz has already been loaded into memory \n",
      "\n",
      "themarketplace.tar.xz has already been loaded into memory \n",
      "\n",
      "cryptomarket.tar.xz has already been loaded into memory \n",
      "\n",
      "cloudnine.tar.xz has already been loaded into memory \n",
      "\n",
      "hydra.tar.xz has already been loaded into memory \n",
      "\n",
      "alphabay.tar.xz has already been loaded into memory \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unpack_all(selected_markets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
