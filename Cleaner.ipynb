{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"/Volumes/Extreme SSD\"\n",
    "DATA_DIR = os.path.join(MAIN_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback information\n",
    "#### Dropping duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2275492 2152745 122747\n"
     ]
    }
   ],
   "source": [
    "data_file = os.path.join(MAIN_DIR, 'data', 'parsed', 'silkroad2', 'feedbacks.pickle')\n",
    "out_file  = os.path.join(MAIN_DIR, 'data', 'final', 'silkroad2', 'feedbacks.pickle')\n",
    "\n",
    "df = pd.read_pickle(data_file)\n",
    "mem = df.memory_usage(deep = True).sum()\n",
    "print(len(df), len(df.drop_duplicates()), len(df) - len(df.drop_duplicates()))\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day(day):\n",
    "    day = day.str.split(' ').str[0]\n",
    "    day = day.replace('today', '0')\n",
    "    pd.to_numeric(day)\n",
    "    return day\n",
    "\n",
    "def to_dt(col):\n",
    "    return pd.to_datetime(col, unit = 's', errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['freshness'] = pd.to_numeric(get_day(df.freshness))\n",
    "df = df\\\n",
    "    .assign(rating = pd.to_numeric(df.rating.str.get(0)),\n",
    "            rtime  = df.stime - df.freshness * 86400)\\\n",
    "    .assign(rtime_dt = lambda df_copy: to_dt(df_copy.rtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage before cleaning                     890426282\n",
      "memory usage before memory usage optimalization  639579799\n",
      "memory usage after memory usage optimalization   460772248\n"
     ]
    }
   ],
   "source": [
    "print('memory usage before cleaning                    ', mem)\n",
    "print('memory usage before memory usage optimalization ', df.memory_usage(deep = True).sum())\n",
    "\n",
    "column_types = {\n",
    "    'name'     : 'category',\n",
    "    'stime'    : 'float32',\n",
    "    'rating'   : pd.Int16Dtype(),\n",
    "    'feedback' : 'object',\n",
    "    'freshness': 'float32',\n",
    "    'rtime'    : 'float32',\n",
    "    'rtime_dt' : 'datetime64'\n",
    "}\n",
    "\n",
    "df = df.astype(column_types)\n",
    "\n",
    "print('memory usage after memory usage optimalization  ', df.memory_usage(deep = True).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropping duplicates\n",
    "\n",
    "In scaped data, the same data is often scraped multiple times. To assure that feedbacks are not included twice duplicates will be dropped. Feedbacks can be uniquely identified by: \n",
    "- `name`\n",
    "- `rating`\n",
    "- `feedback`\n",
    "- `rtime_dt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dropping duplicates: 2152745\n",
      "after dropping duplicates:  2145909\n",
      "\n",
      "6836 duplicate cases were dropped\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate feedbacks from table \n",
    "subset = ['name', 'rating', 'feedback', 'rtime_dt']\n",
    "print(\"before dropping duplicates: {0}\\nafter dropping duplicates:  {1}\\n\\n{2} duplicate cases were dropped\".format(len(df), len(df.drop_duplicates(subset = subset)), len(df) - len(df.drop_duplicates(subset = subset))))\n",
    "\n",
    "df = df.drop_duplicates(subset = subset)\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vendor information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join(MAIN_DIR, 'data', 'parsed', 'silkroad2', 'vendors.pickle')\n",
    "out_file  = os.path.join(MAIN_DIR, 'data', 'final', 'silkroad2', 'vendors.pickle')\n",
    "\n",
    "df = pd.read_pickle(data_file)\n",
    "mem = df.memory_usage(deep = True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_num(col):\n",
    "    \"\"\"\n",
    "    This function returns a numeric value for valid date strings\n",
    "    If the date is today, a zero-value is returned\n",
    "    Otherwise a Null value is returned \n",
    "    \"\"\"\n",
    "    if isinstance(col, str):\n",
    "        if 'today' not in col:\n",
    "            trans_dict = {\n",
    "                'year'  : 365.25,\n",
    "                'month' : 365.25/12,\n",
    "                'day'   : 1,\n",
    "                'hour'  : 1/24\n",
    "            }\n",
    "\n",
    "            value = float(col.split(' ')[0])\n",
    "            unit = col.split(' ')[1]\n",
    "            for key in trans_dict.keys():\n",
    "                if unit in key:\n",
    "                    unit = unit.replace(key, str(trans_dict[key]))\n",
    "            unit = float(unit)\n",
    "\n",
    "            return value * unit\n",
    "        \n",
    "        elif 'today' in col:\n",
    "            return 0\n",
    "        \n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df\\\n",
    "    .assign(\n",
    "        ctime     = df.ctime.str.replace(\"about \", \"\").str.replace('s', '').str.replace(' ago', ''),\n",
    "        otime     = df.otime.str.replace(\"about \", \"\").str.replace('s', '').str.replace(' ago', ''))\\\n",
    "    .assign(\n",
    "        ctime_num = lambda df_copy: df_copy['ctime'].apply(date_to_num),\n",
    "        otime_num = lambda df_copy: df_copy['otime'].apply(date_to_num))\\\n",
    "    .assign(\n",
    "        otime_dt  = lambda df_copy: to_dt(df_copy.stime - df_copy.otime_num * 86400),\n",
    "        ctime_dt  = lambda df_copy: to_dt(df_copy.stime - df_copy.ctime_num * 86400),\n",
    "        stime_dt  = to_dt(df.stime),\n",
    "        score     = df.score.replace('NEW VENDOR', 0).apply(pd.to_numeric))\\\n",
    "    .assign(\n",
    "        score     = lambda df_copy: df_copy.score.mask(df_copy.score > 100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dropping duplicates: 12242\n",
      "after dropping duplicates:  9377\n",
      "\n",
      "2865 duplicate cases were dropped\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate feedbacks from table \n",
    "df['flag'] = df.ctime_dt.dt.strftime('%d%m%Y').astype('category')\n",
    "subset = ['name', 'flag', 'location', 'area']\n",
    "print(\"before dropping duplicates: {0}\\nafter dropping duplicates:   {1}\\n\\n{2} duplicate cases were dropped\".format(len(df), len(df.drop_duplicates(subset = subset)), len(df) - len(df.drop_duplicates(subset = subset))))\n",
    "df = df.drop_duplicates(subset = subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['name', 'stime', 'stime_dt', 'score', 'ctime', 'ctime_num', 'ctime_dt', \n",
    "           'otime', 'otime_num', 'otime_dt', 'location', 'area']\n",
    "\n",
    "df = df.reindex(columns, axis=1)\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage before cleaning                     5708163\n",
      "memory usage before memory usage optimalization  3695920\n",
      "memory usage after memory usage optimalization    640278\n"
     ]
    }
   ],
   "source": [
    "print('memory usage before cleaning                    ', mem)\n",
    "print('memory usage before memory usage optimalization ', df.memory_usage(deep = True).sum())\n",
    "\n",
    "column_types = {\n",
    "    'name'     : 'category',\n",
    "    'stime'    : 'float32',\n",
    "    'stime_dt' : 'datetime64',\n",
    "    'score'    : pd.Int16Dtype(),\n",
    "    'ctime'    : 'category', \n",
    "    'ctime_num': 'float32', \n",
    "    'ctime_dt' : 'datetime64', \n",
    "    'otime'    : 'category', \n",
    "    'otime_num': 'float32', \n",
    "    'otime_dt' : 'datetime64', \n",
    "    'location' : 'category', \n",
    "    'area'     : 'category'\n",
    "}\n",
    "\n",
    "df = df.astype(column_types)\n",
    "\n",
    "print('memory usage after memory usage optimalization   ', df.memory_usage(deep = True).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Item Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22003618 22003618 0\n"
     ]
    }
   ],
   "source": [
    "data_file = os.path.join(MAIN_DIR, 'data', 'parsed', 'silkroad2', 'items.pickle')\n",
    "out_file  = os.path.join(MAIN_DIR, 'data', 'final', 'silkroad2', 'items.pickle')\n",
    "\n",
    "df = pd.read_pickle(data_file)\n",
    "print(len(df), len(df.drop_duplicates()), len(df) - len(df.drop_duplicates()))\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_freshness(col):\n",
    "    #assert that freshness is not missing\n",
    "    new_col = []\n",
    "    for i in col:\n",
    "        if not isinstance(i, (float, int)) and 'day' in i and len(i) < 10:\n",
    "            new_col.append(i)\n",
    "        else:\n",
    "            new_col.append(None)\n",
    "    \n",
    "    return pd.Series(new_col)\n",
    "\n",
    "# mem = df.memory_usage(deep = True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df\\\n",
    "    .assign(\n",
    "        vendor = df.vendor.str.replace('\\\\n', ''),\n",
    "        freshness = clean_freshness(df.freshness).\\\n",
    "            str.replace('s', '')\\\n",
    "            .apply(date_to_num),\n",
    "        rating = df.rating.str.get(0),\n",
    "        price = df.price.str[1:],\n",
    "        stime_str = df.stime_dt)\\\n",
    "    .assign(\n",
    "        rtime = lambda df_copy: df_copy.stime - df_copy.freshness *86400)\\\n",
    "    .assign(\n",
    "        rtime_dt = lambda df_copy: to_dt(df_copy.rtime),\n",
    "        stime_dt = lambda df_copy: to_dt(df_copy.stime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage after memory usage optimalization 5984469841\n"
     ]
    }
   ],
   "source": [
    "# print('memory usage before cleaning', mem)\n",
    "# print('memory usage before memory usage optimalization', df.memory_usage(deep = True).sum())\n",
    "\n",
    "column_types = {\n",
    "    'vendor'   : 'category',\n",
    "    'stime'    : 'float32',\n",
    "    'stime_dt' : 'datetime64',\n",
    "    'stime_str': 'category',\n",
    "    'rating'   : 'float16',\n",
    "    'feedback' : 'object',\n",
    "    'item'     : 'object',\n",
    "    'price'    : 'float32',\n",
    "    'freshness': 'float32',\n",
    "    'rtime'    : 'float32',\n",
    "    'rtime_dt' : 'datetime64',\n",
    "    'loc'      : 'category',\n",
    "    'area'     : 'category'\n",
    "}\n",
    "\n",
    "df = df.astype(column_types)\n",
    "\n",
    "# downcast integer variables\n",
    "df = df\\\n",
    "    .assign(\n",
    "        freshness = pd.Series(df.freshness, dtype=pd.Int16Dtype()),\n",
    "        rating = pd.Series(df.rating, dtype=pd.Int16Dtype()))\n",
    "\n",
    "print('memory usage after memory usage optimalization', df.memory_usage(deep = True).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dropping duplicates: 22003618\n",
      "after dropping duplicates:  1362588\n",
      "\n",
      "20641030 duplicate cases were dropped\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate feedbacks from table \n",
    "df['flag'] = df.rtime_dt.dt.strftime('%d%m%Y').astype('category')\n",
    "subset = ['vendor', 'flag', 'loc', 'feedback', 'rating']\n",
    "print(\"before dropping duplicates: {0}\\nafter dropping duplicates:  {1}\\n\\n{2} duplicate cases were dropped\".format(len(df), len(df.drop_duplicates(subset = subset)), len(df) - len(df.drop_duplicates(subset = subset))))\n",
    "df = df.drop_duplicates(subset = subset)\n",
    "df['location'] = df['loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['vendor', 'stime', 'stime_dt', 'stime_str', 'rating', 'feedback', 'item', 'price',\n",
    "         'freshness', 'rtime', 'rtime_dt', 'location', 'area']\n",
    "\n",
    "df = df.reindex(columns, axis=1)\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor</th>\n",
       "      <th>stime</th>\n",
       "      <th>stime_dt</th>\n",
       "      <th>stime_str</th>\n",
       "      <th>rating</th>\n",
       "      <th>feedback</th>\n",
       "      <th>item</th>\n",
       "      <th>price</th>\n",
       "      <th>freshness</th>\n",
       "      <th>rtime</th>\n",
       "      <th>rtime_dt</th>\n",
       "      <th>location</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213552</th>\n",
       "      <td>haizenberg</td>\n",
       "      <td>1.402430e+09</td>\n",
       "      <td>2014-06-10 20:01:36</td>\n",
       "      <td>2014-04-12</td>\n",
       "      <td>5</td>\n",
       "      <td>Hope it shows up</td>\n",
       "      <td>1G MDMA 87% Purity , QUALITY GUARANTEED</td>\n",
       "      <td>0.066378</td>\n",
       "      <td>5</td>\n",
       "      <td>1.401998e+09</td>\n",
       "      <td>2014-06-05 20:01:36</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>Worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113765</th>\n",
       "      <td>mr whippy pharmaceuticals</td>\n",
       "      <td>1.402430e+09</td>\n",
       "      <td>2014-06-10 19:57:45</td>\n",
       "      <td>2014-03-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Received the next day, product as descripted. ...</td>\n",
       "      <td>0.5g DMT (NN-DMT)</td>\n",
       "      <td>0.080224</td>\n",
       "      <td>51</td>\n",
       "      <td>1.398024e+09</td>\n",
       "      <td>2014-04-20 19:57:45</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202771</th>\n",
       "      <td>trava!95</td>\n",
       "      <td>1.414109e+09</td>\n",
       "      <td>2014-10-24 00:06:26</td>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>5</td>\n",
       "      <td>As always ridiculously fast delivery and the s...</td>\n",
       "      <td>14g STINKY BUD</td>\n",
       "      <td>0.665160</td>\n",
       "      <td>2</td>\n",
       "      <td>1.413936e+09</td>\n",
       "      <td>2014-10-22 00:06:26</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>ItalianMafiaBrussels</td>\n",
       "      <td>1.402429e+09</td>\n",
       "      <td>2014-06-10 19:32:47</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>5</td>\n",
       "      <td>++++</td>\n",
       "      <td>250g Pure MDMA 80%+ Pure Best Quality/Price</td>\n",
       "      <td>7.628963</td>\n",
       "      <td>0</td>\n",
       "      <td>1.402429e+09</td>\n",
       "      <td>2014-06-10 19:32:47</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779978</th>\n",
       "      <td>DeweyDylan93</td>\n",
       "      <td>1.409305e+09</td>\n",
       "      <td>2014-08-29 09:35:54</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>5</td>\n",
       "      <td>Fast shipping. some pills broken and crumbled ...</td>\n",
       "      <td>Big Hawaiian Seeds x 5</td>\n",
       "      <td>0.039533</td>\n",
       "      <td>262</td>\n",
       "      <td>1.386668e+09</td>\n",
       "      <td>2013-12-10 09:35:54</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            vendor         stime            stime_dt  \\\n",
       "213552                  haizenberg  1.402430e+09 2014-06-10 20:01:36   \n",
       "113765   mr whippy pharmaceuticals  1.402430e+09 2014-06-10 19:57:45   \n",
       "1202771                   trava!95  1.414109e+09 2014-10-24 00:06:26   \n",
       "3881          ItalianMafiaBrussels  1.402429e+09 2014-06-10 19:32:47   \n",
       "779978                DeweyDylan93  1.409305e+09 2014-08-29 09:35:54   \n",
       "\n",
       "          stime_str  rating  \\\n",
       "213552   2014-04-12       5   \n",
       "113765   2014-03-10       5   \n",
       "1202771  2014-10-24       5   \n",
       "3881     2013-12-20       5   \n",
       "779978   2014-08-30       5   \n",
       "\n",
       "                                                  feedback  \\\n",
       "213552                                    Hope it shows up   \n",
       "113765   Received the next day, product as descripted. ...   \n",
       "1202771  As always ridiculously fast delivery and the s...   \n",
       "3881                                                  ++++   \n",
       "779978   Fast shipping. some pills broken and crumbled ...   \n",
       "\n",
       "                                                item     price  freshness  \\\n",
       "213552       1G MDMA 87% Purity , QUALITY GUARANTEED  0.066378          5   \n",
       "113765                             0.5g DMT (NN-DMT)  0.080224         51   \n",
       "1202771                               14g STINKY BUD  0.665160          2   \n",
       "3881     250g Pure MDMA 80%+ Pure Best Quality/Price  7.628963          0   \n",
       "779978                        Big Hawaiian Seeds x 5  0.039533        262   \n",
       "\n",
       "                rtime            rtime_dt        location            area  \n",
       "213552   1.401998e+09 2014-06-05 20:01:36  Czech Republic       Worldwide  \n",
       "113765   1.398024e+09 2014-04-20 19:57:45  United Kingdom  United Kingdom  \n",
       "1202771  1.413936e+09 2014-10-22 00:06:26  United Kingdom  United Kingdom  \n",
       "3881     1.402429e+09 2014-06-10 19:32:47         Belgium       Worldwide  \n",
       "779978   1.386668e+09 2013-12-10 09:35:54   United States   United States  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
